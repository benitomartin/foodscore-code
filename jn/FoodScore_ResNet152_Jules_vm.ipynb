{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ac0e704",
   "metadata": {},
   "source": [
    "## Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc95e076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r ~/code/benitomartin/FoodScore/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "239df9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "#Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras import Model \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, EfficientNetB0, EfficientNetB7, ResNet152\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.utils import load_img, img_to_array, to_categorical, image_dataset_from_directory\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "from keras.layers import BatchNormalization\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb34a40c",
   "metadata": {},
   "source": [
    "## Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9f8b163",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = 'UECFOOD100' #UECFOOD256\n",
    "av_number = 130\n",
    "img_number = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "663db74f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>143</td>\n",
       "      <td>370</td>\n",
       "      <td>486</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>208</td>\n",
       "      <td>582</td>\n",
       "      <td>559</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>110</td>\n",
       "      <td>243</td>\n",
       "      <td>410</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>237</td>\n",
       "      <td>286</td>\n",
       "      <td>536</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>761</td>\n",
       "      <td>585</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   img_name  x1   y1   x2   y2  label\n",
       "0         1   0  143  370  486      1\n",
       "1         2  20  208  582  559      1\n",
       "2         3   2  110  243  410      1\n",
       "3         4   0  237  286  536      1\n",
       "4         5   8   28  761  585      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coord = pd.DataFrame()\n",
    "\n",
    "for i in range(1, img_number+1, 1):\n",
    "    path = f\"raw_data/{data_source}/{i}\"\n",
    "    data = pd.read_csv(f\"{path}/bb_info.txt\", sep=' ', header=0, index_col=\"img\")\n",
    "    data_df = pd.DataFrame(data)\n",
    "    data_df[\"label\"] = i\n",
    "    coord = pd.concat([coord, data_df])\n",
    "coord = coord.reset_index()\n",
    "coord = coord.rename(columns={\"img\": \"img_name\"})\n",
    "coord.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d062f76b",
   "metadata": {},
   "source": [
    "### Rescaling and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b79f3fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to normalize bounding box\n",
    "from PIL import Image\n",
    "\n",
    "def normalize_bbox(row):\n",
    "    # Read in the image and get its dimensions\n",
    "    image_path = f\"raw_data/{data_source}/{(row['label'])}/{(row['img_name'])}.jpg\"\n",
    "    image = Image.open(image_path)\n",
    "    width, height  = image.size\n",
    "    \n",
    "    # Normalize the coordinates\n",
    "    x1_norm = row['x1'] / width\n",
    "    y1_norm = row['y1'] / height\n",
    "    x2_norm = row['x2'] / width\n",
    "    y2_norm = row['y2'] / height\n",
    "    \n",
    "    # Return normalized coordinates\n",
    "    return pd.Series({'x1_norm': x1_norm, 'y1_norm': y1_norm, 'x2_norm': x2_norm, 'y2_norm': y2_norm})\n",
    "\n",
    "# Apply the normalize_bbox function to each row of the DataFrame\n",
    "normalized_bbox_df = coord.apply(normalize_bbox, axis=1)\n",
    "\n",
    "# Concatenate the original DataFrame with the new normalized DataFrame\n",
    "rescaled_coord = pd.concat([coord, normalized_bbox_df], axis=1).drop(columns=['x1', 'y1','x2','y2'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4efb29a",
   "metadata": {},
   "source": [
    "### add image paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39287908",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_paths = [f\"raw_data/{data_source}/{int(row['label'])}/{int(row['img_name'])}.jpg\" for _, row in coord.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8477d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaled_coord[\"paths\"] = pd.DataFrame(list_paths).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47c7f6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save DataFrame to csv file\n",
    "#rescaled_coord.to_csv('rescaled_coord_.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9899d5df",
   "metadata": {},
   "source": [
    "### balancing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d28a970b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebalancing(df: pd.DataFrame, classes: list, av_number: int = 10, random_state: int = 1) -> pd.DataFrame:\n",
    "    df_new = df.copy()\n",
    "    for class_ in classes:\n",
    "        class_df = df_new[df_new['label'] == class_]\n",
    "        class_count = len(class_df)\n",
    "        if class_count > av_number:\n",
    "            drop_indices = np.random.choice(class_df.index, class_count - av_number, replace=False)\n",
    "            df_new = df_new.drop(drop_indices)\n",
    "        else:\n",
    "            pass\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e3798c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = list(set(rescaled_coord.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc00b4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = rebalancing(rescaled_coord, classes, av_number= av_number, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d9d7b4",
   "metadata": {},
   "source": [
    "### load downscaled pictures into array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db22c3c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>label</th>\n",
       "      <th>x1_norm</th>\n",
       "      <th>y1_norm</th>\n",
       "      <th>x2_norm</th>\n",
       "      <th>y2_norm</th>\n",
       "      <th>paths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.478750</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>raw_data/UECFOOD100/1/7.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.227083</td>\n",
       "      <td>0.537500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>raw_data/UECFOOD100/1/13.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.561667</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>raw_data/UECFOOD100/1/14.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.35625</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.701562</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>raw_data/UECFOOD100/1/25.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0.51000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.932000</td>\n",
       "      <td>0.778667</td>\n",
       "      <td>raw_data/UECFOOD100/1/26.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    img_name  label  x1_norm   y1_norm   x2_norm   y2_norm  \\\n",
       "6          7      1  0.00000  0.360000  0.478750  1.000000   \n",
       "11        13      1  0.00000  0.227083  0.537500  1.000000   \n",
       "12        14      1  0.00000  0.561667  0.300000  1.000000   \n",
       "21        25      1  0.35625  0.562500  0.701562  1.000000   \n",
       "22        26      1  0.51000  0.333333  0.932000  0.778667   \n",
       "\n",
       "                           paths  \n",
       "6    raw_data/UECFOOD100/1/7.jpg  \n",
       "11  raw_data/UECFOOD100/1/13.jpg  \n",
       "12  raw_data/UECFOOD100/1/14.jpg  \n",
       "21  raw_data/UECFOOD100/1/25.jpg  \n",
       "22  raw_data/UECFOOD100/1/26.jpg  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa041e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shuffled = df.sample(frac=1, random_state=42)\n",
    "df_shuffled.head()\n",
    "df_shuffled = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ca9c622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# color_order = \"RGB\"\n",
    "# dims = (224,224)\n",
    "\n",
    "# images = np.empty((len(df_shuffled), dims[0], dims[1], 3), dtype=np.float32)\n",
    "\n",
    "# for i, path in enumerate(tqdm(df_shuffled.paths.values)):\n",
    "#     #img = Image.open(path)\n",
    "#     img = cv2.imread(path)\n",
    "#     #img = img.resize(dims)/255\n",
    "#     img = cv2.resize(img, dims, interpolation=cv2.INTER_AREA)\n",
    "#     if color_order == \"RGB\":\n",
    "#         img = img[:,:,::-1]\n",
    "#     images[i, :, :, :] = img/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0780a2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('test.npy', 'wb') as f:\n",
    "#    np.save(f, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15e83bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(df_shuffled.label)\n",
    "bboxes = np.array(df_shuffled[['x1_norm','y1_norm','x2_norm','y2_norm']], dtype=\"float32\")\n",
    "paths = np.array(df_shuffled.paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f40a7f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the OneHotEncoder\n",
    "#ohe = OneHotEncoder(sparse = False)\n",
    "#ohe.fit(df_shuffled[['label']])\n",
    "#labels = ohe.transform(df_shuffled[['label']])\n",
    "#labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b19a9745",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lb = LabelBinarizer()\n",
    "#labels = lb.fit_transform(labels)\n",
    "#labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e6c6de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if len(lb.classes_) == 2:\n",
    "#    print(\"two classes\")\n",
    "#    labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9d81f07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.data import Dataset\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "TOTAL_SIZE = len(paths)\n",
    "TRAIN_SIZE = int(0.8*TOTAL_SIZE)\n",
    "\n",
    "TEST_SIZE = int(0.1*TOTAL_SIZE)\n",
    "VAL_SIZE = int(0.1*TOTAL_SIZE)\n",
    "\n",
    "RESIZE = 224\n",
    "WIDTH = RESIZE\n",
    "HEIGHT = RESIZE\n",
    "\n",
    "# Make individual datasets\n",
    "images = Dataset.from_tensor_slices(tf.constant(paths))\n",
    "labels_ds = Dataset.from_tensor_slices(tf.constant(labels))\n",
    "bboxes_ds = Dataset.from_tensor_slices(tf.constant(bboxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5a9f81a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and resize the images\n",
    "# Option 1 with Keras utils\n",
    "# images = images.map(lambda path: \n",
    "#      tf.keras.utils.load_img(path, target_size=(HEIGHT, WIDTH)),\n",
    "#      num_parallel_calls=AUTOTUNE\n",
    "#      )\n",
    "\n",
    "# images = images.map(tf.keras.utils.img_to_array)\n",
    "\n",
    "# # # Option 2 with native tf\n",
    "images = images.map(tf.io.read_file, num_parallel_calls=AUTOTUNE)\n",
    "images = images.map(tf.io.decode_jpeg, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5b623ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#next(images.take(1).as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "540375b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images = images.map(lambda img:\n",
    "     tf.image.resize(img, [HEIGHT, WIDTH]),\n",
    "     num_parallel_calls=AUTOTUNE\n",
    "     )\n",
    "\n",
    "# Build the multi output target\n",
    "targets = Dataset.zip((labels_ds, bboxes_ds))\n",
    "\n",
    "targets = targets.map(lambda label, bbox:\n",
    "    {\n",
    "        'class_label': label,\n",
    "        'bounding_box': bbox,\n",
    "    },\n",
    "    num_parallel_calls=AUTOTUNE\n",
    "    )\n",
    "\n",
    "# targets = targets.map(lambda label, bbox:\n",
    "#     (\n",
    "#         tf.cast(label, tf.float32),\n",
    "#         tf.cast(bbox, tf.float32),\n",
    "#     ),\n",
    "#     num_parallel_calls=AUTOTUNE\n",
    "# )\n",
    "\n",
    "# Put it all together\n",
    "ds = Dataset.zip((images, targets))\n",
    "#ds = targets\n",
    "\n",
    "# Try caching if there is enough memory (VM only)\n",
    "#ds = ds.cache()\n",
    "\n",
    "train_ds = ds.take(TRAIN_SIZE)\n",
    "tv_ds = ds.skip(TRAIN_SIZE)\n",
    "val_ds = tv_ds.take(VAL_SIZE)\n",
    "test_ds = tv_ds.skip(VAL_SIZE).take(TEST_SIZE)\n",
    "\n",
    "#tv_ds, test_ds = tf.keras.utils.split_dataset(ds, right_size=TEST_SIZE, shuffle=False)\n",
    "#train_ds, val_ds = tf.keras.utils.split_dataset(tv_ds, right_size=VAL_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "train_ds = train_ds.batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "823ebc6f-6ab4-448b-953e-17057f187f92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#next(test_ds.batch(32).take(2).as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0dc32e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tvImages, testImages,tvLabels, testLabels,tvBBoxes, testBBoxes,tvPaths, testPaths=\\\n",
    "# train_test_split(images,\n",
    "#                  labels,\n",
    "#                  bboxes,\n",
    "#                  paths,\n",
    "#                  test_size=0.10,\n",
    "#                  random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dc3b1904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainImages, valImages,trainLabels, valLabels,trainBBoxes, valBBoxes, trainPaths, valPaths=\\\n",
    "# train_test_split(tvImages,\n",
    "#                  tvLabels,\n",
    "#                  tvBBoxes,\n",
    "#                  tvPaths,\n",
    "#                  test_size=0.30,\n",
    "#                  random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fe1a9f-1438-435d-9213-e415e737e2ce",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0a31e129",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#set(df_shuffled.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "91a6307a-e215-46f3-9d95-38b04d28e486",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model = EfficientNetB7(weights=\"imagenet\",\n",
    "#            include_top=False,\n",
    "#            input_tensor=layers.Input(shape=(224, 224, 3)),\n",
    "#            drop_connect_rate=0.2)\n",
    "#model = EfficientNetB7(\n",
    "#        input_shape=(224, 224, 3),\n",
    "#        weights='imagenet',\n",
    "#        include_top=False\n",
    "#   )\n",
    "#model = ResNet152(\n",
    "#    include_top=True,\n",
    "#   weights='imagenet',\n",
    "#    input_tensor=layers.Input(shape=(224, 224, 3))\n",
    "#   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f7af99e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=(224, 224, 3))\n",
    "x = layers.RandomBrightness(0.3)(inputs)\n",
    "\n",
    "x = preprocess_input(inputs)\n",
    "\n",
    "# Load pre-trained ResNet152 model\n",
    "base_model = ResNet152(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_tensor=inputs\n",
    ")\n",
    "\n",
    "x = base_model(x)\n",
    "\n",
    "\n",
    "#Freeze layers in base model\n",
    "#for layer in base_model.layers[:-10]:\n",
    "#    layer.trainable = False\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "# Region Proposal Network\n",
    "#rpn = layers.Conv2D(filters=256, kernel_size=(3,3), strides=1, padding=\"same\", activation=\"gelu\")(base_model.output)\n",
    "#rpn_class = layers.Conv2D(filters=2, kernel_size=(1,1), activation=\"softmax\", name=\"rpn_class\")(rpn)\n",
    "#rpn_bbox = layers.Conv2D(filters=4, kernel_size=(1,1), activation=\"gelu\", name=\"rpn_bbox\")(rpn)\n",
    "\n",
    "# Classification and Bounding Box Regression Heads\n",
    "flatten = layers.GlobalAveragePooling2D()(x)\n",
    "flatten = layers.Flatten()(flatten)\n",
    "\n",
    "#bbox_head = layers.Dense(128, activation=\"gelu\",kernel_regularizer=l2(0.01))(flatten)\n",
    "#bbox_head = layers.BatchNormalization()(bbox_head)\n",
    "#bbox_head = layers.Dense(64, activation=\"gelu\",kernel_regularizer=l2(0.01))(bbox_head)\n",
    "#bbox_head = layers.BatchNormalization()(bbox_head)\n",
    "#bbox_head = layers.Dense(32, activation=\"gelu\",kernel_regularizer=l2(0.01))(bbox_head)\n",
    "#bbox_head = layers.BatchNormalization()(bbox_head)\n",
    "bbox_head = layers.Dense(4, activation=\"sigmoid\", name=\"bounding_box\",kernel_regularizer=l2(0.01))(flatten)\n",
    "\n",
    "#softmax_head = layers.Dense(128, activation=\"gelu\",kernel_regularizer=l2(0.02))(flatten)\n",
    "#softmax_head = layers.Dropout(0.5)(softmax_head)\n",
    "#softmax_head = layers.Dense(64, activation=\"gelu\",kernel_regularizer=l2(0.04))(softmax_head)\n",
    "#softmax_head = layers.Dropout(0.5)(softmax_head)\n",
    "softmax_head = layers.Dense(len(set(df_shuffled.label)), activation=\"softmax\", name=\"class_label\",kernel_regularizer=l2(0.01))(flatten)\n",
    "\n",
    "# Combine the model heads\n",
    "outputs = [bbox_head, softmax_head]\n",
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bcc0bcf5-27a3-40ad-afff-a866e4968c7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "losses = {\n",
    "    \"class_label\": 'sparse_categorical_crossentropy', #categorical_crossentropy\n",
    "    \"bounding_box\": \"mse\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f310cfdc-d5d4-44a6-bb08-0a1c8bb5a50f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lossWeights = {\n",
    "    \"class_label\": 1.0,\n",
    "    \"bounding_box\": 1.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "28703d3b-b0d6-4531-84a4-570bf5d9478d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#trainTargets = {\n",
    "#    \"class_label\": trainLabels,\n",
    "#    \"bounding_box\": trainBBoxes\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "69a31368-8f9e-4eec-9464-80a9b6ff156c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#testTargets = {\n",
    "#    \"class_label\": testLabels,\n",
    "#    \"bounding_box\": testBBoxes\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e007a16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#valTargets = {\n",
    "#    \"class_label\": valLabels,\n",
    "#    \"bounding_box\": valBBoxes\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "abbf8942-5e42-44b6-a1d2-ade79a97f7c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    \"class_label\": \"sparse_categorical_accuracy\", #categorical_accuracy\n",
    "    \"bounding_box\": MeanIoU(num_classes=len(set(df_shuffled.label)))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "466bd563-30fe-4ae0-9e07-bb7a43f1d984",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "opt = Adam(0.01)\n",
    "\n",
    "model.compile(loss=losses, \n",
    "              optimizer=opt, \n",
    "              metrics=metrics, \n",
    "              loss_weights=lossWeights)\n",
    "#print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "61ba612d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# es = EarlyStopping(monitor = 'val_class_label_categorical_accuracy',\n",
    "#                    patience = 10,\n",
    "#                    verbose = 0,\n",
    "#                    restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "22e62ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "295/300 [============================>.] - ETA: 1s - loss: 88.6307 - bounding_box_loss: 0.0369 - class_label_loss: 85.4067 - bounding_box_mean_io_u_3: 0.4726 - class_label_sparse_categorical_accuracy: 0.0155"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 14:18:44.918401: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - ETA: 0s - loss: 89.3260 - bounding_box_loss: 0.0368 - class_label_loss: 86.0432 - bounding_box_mean_io_u_3: 0.4727 - class_label_sparse_categorical_accuracy: 0.0153"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 14:19:03.705980: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 99s 300ms/step - loss: 89.3260 - bounding_box_loss: 0.0368 - class_label_loss: 86.0432 - bounding_box_mean_io_u_3: 0.4727 - class_label_sparse_categorical_accuracy: 0.0153 - val_loss: 150.6168 - val_bounding_box_loss: 0.0410 - val_class_label_loss: 143.0517 - val_bounding_box_mean_io_u_3: 0.4200 - val_class_label_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/500\n",
      "295/300 [============================>.] - ETA: 1s - loss: 100.5181 - bounding_box_loss: 0.0357 - class_label_loss: 90.8287 - bounding_box_mean_io_u_3: 0.4442 - class_label_sparse_categorical_accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 14:20:15.495334: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - ETA: 0s - loss: 101.1229 - bounding_box_loss: 0.0355 - class_label_loss: 91.3846 - bounding_box_mean_io_u_3: 0.4443 - class_label_sparse_categorical_accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 14:20:30.246704: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 85s 284ms/step - loss: 101.1229 - bounding_box_loss: 0.0355 - class_label_loss: 91.3846 - bounding_box_mean_io_u_3: 0.4443 - class_label_sparse_categorical_accuracy: 0.0000e+00 - val_loss: 166.5504 - val_bounding_box_loss: 0.0737 - val_class_label_loss: 153.2255 - val_bounding_box_mean_io_u_3: 0.4167 - val_class_label_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 3/500\n",
      "297/300 [============================>.] - ETA: 0s - loss: 84.3685 - bounding_box_loss: 0.0353 - class_label_loss: 69.4962 - bounding_box_mean_io_u_3: 0.4651 - class_label_sparse_categorical_accuracy: 0.0213"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 14:21:41.246999: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - ETA: 0s - loss: 84.3934 - bounding_box_loss: 0.0352 - class_label_loss: 69.5137 - bounding_box_mean_io_u_3: 0.4654 - class_label_sparse_categorical_accuracy: 0.0211"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 14:21:55.361340: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 85s 283ms/step - loss: 84.3934 - bounding_box_loss: 0.0352 - class_label_loss: 69.5137 - bounding_box_mean_io_u_3: 0.4654 - class_label_sparse_categorical_accuracy: 0.0211 - val_loss: 131.6774 - val_bounding_box_loss: 0.0594 - val_class_label_loss: 115.6960 - val_bounding_box_mean_io_u_3: 0.4167 - val_class_label_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 4/500\n",
      "295/300 [============================>.] - ETA: 1s - loss: 80.1417 - bounding_box_loss: 0.0359 - class_label_loss: 62.5575 - bounding_box_mean_io_u_3: 0.4876 - class_label_sparse_categorical_accuracy: 0.0311"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_22078/2138185189.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m     callbacks = [early_stopping, \n\u001b[1;32m     28\u001b[0m                  \u001b[0;31m#model_checkpoint,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                  tensorboard_callback],\n\u001b[0m\u001b[1;32m     30\u001b[0m     )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1562\u001b[0m                         ):\n\u001b[1;32m   1563\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1564\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1565\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1566\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2495\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2496\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2497\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2499\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1861\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1863\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1864\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train\n",
    "working_dir = \"/home/jupyter/experiments_is\"\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "exp_dir = os.path.join(working_dir, f\"exp-{timestamp}\")\n",
    "logdir = os.path.join(exp_dir, \"logs\")\n",
    "#checkpoint_file = os.path.join(exp_dir, \"ckpt\", f\"weights-{epoch:02d}-{sparse_categorical_accuracy:.3f}.h5\")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor = 'val_class_label_sparse_categorical_accuracy',\n",
    "    patience = 10,\n",
    "    verbose = 0,\n",
    "    restore_best_weights = True\n",
    ")\n",
    "\n",
    "#model_checkpoint = ModelCheckpoint(\n",
    "#    filepath=checkpoint_file,\n",
    "#    verbose=0,\n",
    "#)\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=500,\n",
    "    verbose=1,\n",
    "    callbacks = [early_stopping, \n",
    "                 #model_checkpoint,\n",
    "                 tensorboard_callback],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac2155e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(\n",
    "#     trainImages,\n",
    "#     trainTargets,\n",
    "#     validation_data=(valImages, valTargets),\n",
    "#     batch_size=128,\n",
    "#     epochs=100,\n",
    "#     verbose=1,\n",
    "#     callbacks=[es],\n",
    "#     #use_multiprocessing=True,\n",
    "#     #workers = 8\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94b5f71",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc21d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet50/100img\n",
    "\n",
    "#model.save('test.h5')# save model\n",
    "model.save(os.path.join(exp_dir, 'model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1520b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "!break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e516032e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(testPaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db170ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a txt file to save the paths of the test images\n",
    "\n",
    "f = open(\"test_path.txt\", \"w\")\n",
    "f.write(\"\\n\".join(testPaths))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec5c6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of images paths\n",
    "\n",
    "path = \"test_path.txt\"\n",
    "filenames = open(path).read().strip().split(\"\\n\")\n",
    "imagePaths = []\n",
    "\n",
    "for f in filenames:\n",
    "    imagePaths.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30355f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IoU Calculation function\n",
    "\n",
    "def calculate_iou(boxA, boxB):\n",
    "    # boxA (true) and boxB(precicted) are lists with 4 elements: [x1, y1, x2, y2]\n",
    "    \n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "\n",
    "    # compute the area of both the prediction and ground-truth rectangles\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "\n",
    "    # compute the intersection over union by taking the intersection area\n",
    "    # and dividing it by the sum of prediction + ground-truth areas - intersection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "\n",
    "    # return the intersection over union value\n",
    "    return iou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445ddff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df of labels id and category names\n",
    "\n",
    "path_categories = f\"../raw_data/UECFOOD100\"\n",
    "\n",
    "categories = pd.read_csv(f\"{path_categories}/category.txt\", sep='\\t')\n",
    "\n",
    "category_df = pd.DataFrame(categories)\n",
    "\n",
    "category_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3a1f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = category_df.id.values.tolist()\n",
    "print(id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e22b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_list = category_df.name.values.tolist()\n",
    "print(category_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6e2b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the test images to get the predicted bbox, true bbox and IoU\n",
    "\n",
    "for imagePath in imagePaths:\n",
    "\n",
    "    # load the input image\n",
    "    image = load_img(imagePath, target_size=(224, 224))\n",
    "    image = img_to_array(image) / 255.0\n",
    "    image = np.expand_dims(image, axis=0)  \n",
    "\n",
    "    # predict coordinates and classes\n",
    "    (boxPreds, labelPreds) = model.predict(image)\n",
    "    (pred_x1, pred_y1, pred_x2, pred_y2) = boxPreds[0]\n",
    "        \n",
    "    print(f\"My predicted bounding box has the following coordinates {boxPreds[0]}\")\n",
    "    print(f\"My predicted labels has the following probabilities {labelPreds[0]}\")\n",
    "    \n",
    "    # determine the class label with the largest predicted probability\n",
    "    i = np.argmax(labelPreds, axis=1)\n",
    "    label = lb.classes_[i][0]\n",
    "    \n",
    "    print(f\"We have {lb.classes_} classes\")\n",
    "    print(f\"The class with the highest probability is class number {label}\")\n",
    "    \n",
    "    # Find the category using the index of id and name  in category_df\n",
    "    index_category = id_list.index(label)  \n",
    "    print(f\"The food class is {category_list[index_category]}\")\n",
    "    \n",
    "    # load the input image (in OpenCV format)\n",
    "    image = cv2.imread(imagePath)\n",
    "    (h, w) = image.shape[:2]\n",
    "    \n",
    "   \n",
    "    # scale the predicted bounding box coordinates based on the image dimensions       \n",
    "    pred_x1 = int(pred_x1 * w)\n",
    "    pred_y1 = int(pred_y1 * h)\n",
    "    pred_x2 = int(pred_x2 * w)\n",
    "    pred_y2 = int(pred_y2 * h)\n",
    "\n",
    "    index_image = imagePaths.index(imagePath)\n",
    "    \n",
    "    true_x1 = int(testBBoxes[index_image][0] * w)\n",
    "    true_y1 = int(testBBoxes[index_image][1] * h)\n",
    "    true_x2 = int(testBBoxes[index_image][2] * w)\n",
    "    true_y2 = int(testBBoxes[index_image][3] * h)\n",
    "    \n",
    "    true_box = [true_x1, true_y1, true_x2, true_y2]\n",
    "    pred_box = [pred_x1, pred_y1, pred_x2, pred_y2]\n",
    "    \n",
    "    iou = calculate_iou(true_box, pred_box)  \n",
    "   \n",
    "    print(f\"My predicted bounding box in red has the following coordinates {(pred_x1, pred_y1, pred_x2, pred_y2)}\")\n",
    "    print(f\"My true bounding box in blue has the following coordinates {(true_x1, true_y1, true_x2, true_y2)}\")\n",
    "    print(f\"My IoU is {iou:.2f}\")\n",
    "   \n",
    "\n",
    "\n",
    "    \"\"\" Plot them on image \"\"\"\n",
    "    cv2.rectangle(image, (true_x1, true_y1), (true_x2, true_y2), (255, 0, 0), 2) ## BLUE\n",
    "    cv2.rectangle(image, (pred_x1, pred_y1), (pred_x2, pred_y2), (0, 0, 255), 2) ## RED\n",
    "    \n",
    "       \n",
    "    cv2.putText(image, f\"My IoU is {iou:.2f}\", (true_x1, true_y1-20), cv2.FONT_HERSHEY_SIMPLEX, 0.65, (0, 255, 0), 2)\n",
    "    \n",
    "    imgplot = plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype('uint8'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f62974",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8b15da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29297b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac586f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43687114",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-10.m104",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-10:m104"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
